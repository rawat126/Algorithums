{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data used here is created manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>axis 1</th>\n",
       "      <th>axis 2</th>\n",
       "      <th>axis 3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>20.35</td>\n",
       "      <td>0.064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.3</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.8</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    axis 1  axis 2  axis 3  Label\n",
       "0      1.0   20.00   0.080      1\n",
       "1      4.0   30.00   0.073      1\n",
       "2      6.0   20.35   0.064      1\n",
       "3      3.0   21.00   0.092      1\n",
       "4      2.5   25.00   0.084      1\n",
       "5      3.3   21.00   0.079      1\n",
       "6      1.8   20.00   0.180      1\n",
       "7     12.0   11.00   0.750      0\n",
       "8     10.0    9.00   0.320      0\n",
       "9     13.0   13.00   0.430      0\n",
       "10    11.0   12.00   0.650      0\n",
       "11    17.0   10.00   0.350      0\n",
       "12    14.0   10.00   0.640      0"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Data with multiple axis and Labels\n",
    "df = pd.DataFrame({'axis 1':[1,4,6,3,2.5,3.3,1.8,12,10,13,11,17,14],\n",
    "                   'axis 2':[20,30,20.35,21,25,21,20,11,9,13,12,10,10],\n",
    "                   'axis 3':[0.08,0.073,0.064,0.092,0.084,0.079,0.18,0.75,0.32,0.43,0.65,0.35,0.64],\n",
    "                   'Label':[1,1,1,1,1,1,1,0,0,0,0,0,0]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random weight intializationn with low values\n",
    "weights = np.random.randn(3)*1e-04\n",
    "\n",
    "# bais is taken as 1\n",
    "bais = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization...\n",
    "inputs = np.asarray(df.iloc[:,0:3])\n",
    "inputs[:,0] = (inputs[:,0]-min(inputs[:,0]))/(max(inputs[:,0])-min(inputs[:,0]))\n",
    "inputs[:,1] = (inputs[:,1]-min(inputs[:,1]))/(max(inputs[:,1])-min(inputs[:,1]))\n",
    "inputs[:,2] = (inputs[:,2]-min(inputs[:,2]))/(max(inputs[:,2])-min(inputs[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_training(df,inputs,weights,bais,eta=0.02):\n",
    "    # intializing the necessary variables....\n",
    "    # displaying the starting weights..\n",
    "    print('Initial weights : ',weights,'\\n')\n",
    "    l=[]\n",
    "    acc = []\n",
    "    count=1\n",
    "    print('Model Training Started......')\n",
    "    time.sleep(2)\n",
    "    print()\n",
    "    \n",
    "    # model Training with 210 epochs....\n",
    "    for i in range(210):   \n",
    "        val = [sum(i) for i in (inputs*weights)+ bais]\n",
    "        \n",
    "        y_pred = 1/(1+np.exp(-np.array(val)))\n",
    "        y_act = np.asarray(df['Label'])\n",
    "        loss = sum(((y_act-y_pred)**2)/2)\n",
    "        \n",
    "        # weights and bais updation...\n",
    "        weights[0] = weights[0] - eta*inputs[:,0].mean()\n",
    "        weights[1] = weights[1] - eta*inputs[:,1].mean()\n",
    "        weights[2] = weights[2] - eta*inputs[:,2].mean()\n",
    "        bais = bais - 0.002*1\n",
    "        \n",
    "        print('epoch {}'.format(i),'==========================================')\n",
    "        print('Loss : ',loss)\n",
    "        l.append(loss)\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print('current weights : ',weights)\n",
    "    print('current bais : ',bais)\n",
    "    \n",
    "\n",
    "    return (weights,bais,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  [ 3.41583793e-05 -3.03379606e-05  3.64489073e-04] \n",
      "\n",
      "Model Training Started......\n",
      "\n",
      "epoch 0 ==========================================\n",
      "Loss :  2.730133488073286\n",
      "epoch 1 ==========================================\n",
      "Loss :  2.725845294886653\n",
      "epoch 2 ==========================================\n",
      "Loss :  2.7214942727706752\n",
      "epoch 3 ==========================================\n",
      "Loss :  2.7170796982870002\n",
      "epoch 4 ==========================================\n",
      "Loss :  2.712600846769555\n",
      "epoch 5 ==========================================\n",
      "Loss :  2.7080569926190874\n",
      "epoch 6 ==========================================\n",
      "Loss :  2.7034474096097023\n",
      "epoch 7 ==========================================\n",
      "Loss :  2.698771371207673\n",
      "epoch 8 ==========================================\n",
      "Loss :  2.6940281509027595\n",
      "epoch 9 ==========================================\n",
      "Loss :  2.6892170225523033\n",
      "epoch 10 ==========================================\n",
      "Loss :  2.6843372607383325\n",
      "epoch 11 ==========================================\n",
      "Loss :  2.679388141137926\n",
      "epoch 12 ==========================================\n",
      "Loss :  2.674368940907084\n",
      "epoch 13 ==========================================\n",
      "Loss :  2.6692789390783376\n",
      "epoch 14 ==========================================\n",
      "Loss :  2.6641174169723207\n",
      "epoch 15 ==========================================\n",
      "Loss :  2.658883658623541\n",
      "epoch 16 ==========================================\n",
      "Loss :  2.6535769512205682\n",
      "epoch 17 ==========================================\n",
      "Loss :  2.6481965855608354\n",
      "epoch 18 ==========================================\n",
      "Loss :  2.642741856520281\n",
      "epoch 19 ==========================================\n",
      "Loss :  2.6372120635380067\n",
      "epoch 20 ==========================================\n",
      "Loss :  2.6316065111161464\n",
      "epoch 21 ==========================================\n",
      "Loss :  2.6259245093351145\n",
      "epoch 22 ==========================================\n",
      "Loss :  2.6201653743844058\n",
      "epoch 23 ==========================================\n",
      "Loss :  2.614328429109086\n",
      "epoch 24 ==========================================\n",
      "Loss :  2.6084130035721254\n",
      "epoch 25 ==========================================\n",
      "Loss :  2.6024184356326825\n",
      "epoch 26 ==========================================\n",
      "Loss :  2.5963440715404635\n",
      "epoch 27 ==========================================\n",
      "Loss :  2.590189266546239\n",
      "epoch 28 ==========================================\n",
      "Loss :  2.5839533855285928\n",
      "epoch 29 ==========================================\n",
      "Loss :  2.577635803636974\n",
      "epoch 30 ==========================================\n",
      "Loss :  2.5712359069510655\n",
      "epoch 31 ==========================================\n",
      "Loss :  2.564753093156515\n",
      "epoch 32 ==========================================\n",
      "Loss :  2.558186772236998\n",
      "epoch 33 ==========================================\n",
      "Loss :  2.5515363671826057\n",
      "epoch 34 ==========================================\n",
      "Loss :  2.544801314714488\n",
      "epoch 35 ==========================================\n",
      "Loss :  2.537981066025699\n",
      "epoch 36 ==========================================\n",
      "Loss :  2.531075087538112\n",
      "epoch 37 ==========================================\n",
      "Loss :  2.5240828616752986\n",
      "epoch 38 ==========================================\n",
      "Loss :  2.5170038876512018\n",
      "epoch 39 ==========================================\n",
      "Loss :  2.5098376822744086\n",
      "epoch 40 ==========================================\n",
      "Loss :  2.502583780767806\n",
      "epoch 41 ==========================================\n",
      "Loss :  2.495241737603371\n",
      "epoch 42 ==========================================\n",
      "Loss :  2.487811127351786\n",
      "epoch 43 ==========================================\n",
      "Loss :  2.4802915455465824\n",
      "epoch 44 ==========================================\n",
      "Loss :  2.47268260956243\n",
      "epoch 45 ==========================================\n",
      "Loss :  2.464983959507181\n",
      "epoch 46 ==========================================\n",
      "Loss :  2.457195259127228\n",
      "epoch 47 ==========================================\n",
      "Loss :  2.449316196725706\n",
      "epoch 48 ==========================================\n",
      "Loss :  2.441346486092999\n",
      "epoch 49 ==========================================\n",
      "Loss :  2.433285867449011\n",
      "epoch 50 ==========================================\n",
      "Loss :  2.425134108396573\n",
      "epoch 51 ==========================================\n",
      "Loss :  2.41689100488535\n",
      "epoch 52 ==========================================\n",
      "Loss :  2.4085563821855343\n",
      "epoch 53 ==========================================\n",
      "Loss :  2.4001300958705905\n",
      "epoch 54 ==========================================\n",
      "Loss :  2.391612032808257\n",
      "epoch 55 ==========================================\n",
      "Loss :  2.3830021121589486\n",
      "epoch 56 ==========================================\n",
      "Loss :  2.374300286380688\n",
      "epoch 57 ==========================================\n",
      "Loss :  2.3655065422396016\n",
      "epoch 58 ==========================================\n",
      "Loss :  2.356620901824998\n",
      "epoch 59 ==========================================\n",
      "Loss :  2.347643423567982\n",
      "epoch 60 ==========================================\n",
      "Loss :  2.3385742032624965\n",
      "epoch 61 ==========================================\n",
      "Loss :  2.3294133750876522\n",
      "epoch 62 ==========================================\n",
      "Loss :  2.320161112630135\n",
      "epoch 63 ==========================================\n",
      "Loss :  2.3108176299054355\n",
      "epoch 64 ==========================================\n",
      "Loss :  2.3013831823765907\n",
      "epoch 65 ==========================================\n",
      "Loss :  2.2918580679690796\n",
      "epoch 66 ==========================================\n",
      "Loss :  2.282242628080453\n",
      "epoch 67 ==========================================\n",
      "Loss :  2.2725372485832365\n",
      "epoch 68 ==========================================\n",
      "Loss :  2.2627423608195847\n",
      "epoch 69 ==========================================\n",
      "Loss :  2.252858442586125\n",
      "epoch 70 ==========================================\n",
      "Loss :  2.2428860191073707\n",
      "epoch 71 ==========================================\n",
      "Loss :  2.2328256639960378\n",
      "epoch 72 ==========================================\n",
      "Loss :  2.222678000198559\n",
      "epoch 73 ==========================================\n",
      "Loss :  2.2124437009240316\n",
      "epoch 74 ==========================================\n",
      "Loss :  2.2021234905548086\n",
      "epoch 75 ==========================================\n",
      "Loss :  2.191718145536879\n",
      "epoch 76 ==========================================\n",
      "Loss :  2.1812284952481757\n",
      "epoch 77 ==========================================\n",
      "Loss :  2.170655422842873\n",
      "epoch 78 ==========================================\n",
      "Loss :  2.159999866069738\n",
      "epoch 79 ==========================================\n",
      "Loss :  2.1492628180625517\n",
      "epoch 80 ==========================================\n",
      "Loss :  2.1384453281005817\n",
      "epoch 81 ==========================================\n",
      "Loss :  2.127548502337086\n",
      "epoch 82 ==========================================\n",
      "Loss :  2.1165735044937737\n",
      "epoch 83 ==========================================\n",
      "Loss :  2.1055215565191725\n",
      "epoch 84 ==========================================\n",
      "Loss :  2.0943939392087967\n",
      "epoch 85 ==========================================\n",
      "Loss :  2.0831919927850335\n",
      "epoch 86 ==========================================\n",
      "Loss :  2.071917117434643\n",
      "epoch 87 ==========================================\n",
      "Loss :  2.0605707738017744\n",
      "epoch 88 ==========================================\n",
      "Loss :  2.049154483434411\n",
      "epoch 89 ==========================================\n",
      "Loss :  2.0376698291821462\n",
      "epoch 90 ==========================================\n",
      "Loss :  2.026118455543239\n",
      "epoch 91 ==========================================\n",
      "Loss :  2.0145020689588984\n",
      "epoch 92 ==========================================\n",
      "Loss :  2.0028224380527715\n",
      "epoch 93 ==========================================\n",
      "Loss :  1.9910813938136587\n",
      "epoch 94 ==========================================\n",
      "Loss :  1.979280829719507\n",
      "epoch 95 ==========================================\n",
      "Loss :  1.9674227018007755\n",
      "epoch 96 ==========================================\n",
      "Loss :  1.955509028641332\n",
      "epoch 97 ==========================================\n",
      "Loss :  1.9435418913150813\n",
      "epoch 98 ==========================================\n",
      "Loss :  1.931523433256602\n",
      "epoch 99 ==========================================\n",
      "Loss :  1.9194558600641385\n",
      "epoch 100 ==========================================\n",
      "Loss :  1.9073414392333614\n",
      "epoch 101 ==========================================\n",
      "Loss :  1.8951824998204163\n",
      "epoch 102 ==========================================\n",
      "Loss :  1.8829814320328448\n",
      "epoch 103 ==========================================\n",
      "Loss :  1.8707406867470806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104 ==========================================\n",
      "Loss :  1.858462774951319\n",
      "epoch 105 ==========================================\n",
      "Loss :  1.8461502671126702\n",
      "epoch 106 ==========================================\n",
      "Loss :  1.8338057924676208\n",
      "epoch 107 ==========================================\n",
      "Loss :  1.8214320382349585\n",
      "epoch 108 ==========================================\n",
      "Loss :  1.8090317487504377\n",
      "epoch 109 ==========================================\n",
      "Loss :  1.7966077245226009\n",
      "epoch 110 ==========================================\n",
      "Loss :  1.7841628212093152\n",
      "epoch 111 ==========================================\n",
      "Loss :  1.7716999485147233\n",
      "epoch 112 ==========================================\n",
      "Loss :  1.7592220690064675\n",
      "epoch 113 ==========================================\n",
      "Loss :  1.7467321968531928\n",
      "epoch 114 ==========================================\n",
      "Loss :  1.7342333964825043\n",
      "epoch 115 ==========================================\n",
      "Loss :  1.7217287811597095\n",
      "epoch 116 ==========================================\n",
      "Loss :  1.7092215114878588\n",
      "epoch 117 ==========================================\n",
      "Loss :  1.6967147938297498\n",
      "epoch 118 ==========================================\n",
      "Loss :  1.6842118786527516\n",
      "epoch 119 ==========================================\n",
      "Loss :  1.671716058797475\n",
      "epoch 120 ==========================================\n",
      "Loss :  1.6592306676714923\n",
      "epoch 121 ==========================================\n",
      "Loss :  1.6467590773694905\n",
      "epoch 122 ==========================================\n",
      "Loss :  1.6343046967214239\n",
      "epoch 123 ==========================================\n",
      "Loss :  1.6218709692704074\n",
      "epoch 124 ==========================================\n",
      "Loss :  1.6094613711822796\n",
      "epoch 125 ==========================================\n",
      "Loss :  1.5970794090889286\n",
      "epoch 126 ==========================================\n",
      "Loss :  1.5847286178676698\n",
      "epoch 127 ==========================================\n",
      "Loss :  1.5724125583591217\n",
      "epoch 128 ==========================================\n",
      "Loss :  1.560134815026201\n",
      "epoch 129 ==========================================\n",
      "Loss :  1.5478989935570393\n",
      "epoch 130 ==========================================\n",
      "Loss :  1.5357087184147584\n",
      "epoch 131 ==========================================\n",
      "Loss :  1.5235676303372334\n",
      "epoch 132 ==========================================\n",
      "Loss :  1.5114793837900942\n",
      "epoch 133 ==========================================\n",
      "Loss :  1.4994476443763831\n",
      "epoch 134 ==========================================\n",
      "Loss :  1.4874760862064147\n",
      "epoch 135 ==========================================\n",
      "Loss :  1.47556838923152\n",
      "epoch 136 ==========================================\n",
      "Loss :  1.4637282365454816\n",
      "epoch 137 ==========================================\n",
      "Loss :  1.4519593116575709\n",
      "epoch 138 ==========================================\n",
      "Loss :  1.4402652957412276\n",
      "epoch 139 ==========================================\n",
      "Loss :  1.4286498648624852\n",
      "epoch 140 ==========================================\n",
      "Loss :  1.417116687192371\n",
      "epoch 141 ==========================================\n",
      "Loss :  1.4056694202075397\n",
      "epoch 142 ==========================================\n",
      "Loss :  1.3943117078835132\n",
      "epoch 143 ==========================================\n",
      "Loss :  1.3830471778849092\n",
      "epoch 144 ==========================================\n",
      "Loss :  1.3718794387571118\n",
      "epoch 145 ==========================================\n",
      "Loss :  1.3608120771238525\n",
      "epoch 146 ==========================================\n",
      "Loss :  1.3498486548951938\n",
      "epoch 147 ==========================================\n",
      "Loss :  1.3389927064904081\n",
      "epoch 148 ==========================================\n",
      "Loss :  1.3282477360802485\n",
      "epoch 149 ==========================================\n",
      "Loss :  1.317617214853069\n",
      "epoch 150 ==========================================\n",
      "Loss :  1.307104578309242\n",
      "epoch 151 ==========================================\n",
      "Loss :  1.2967132235882604\n",
      "epoch 152 ==========================================\n",
      "Loss :  1.2864465068328592\n",
      "epoch 153 ==========================================\n",
      "Loss :  1.2763077405944272\n",
      "epoch 154 ==========================================\n",
      "Loss :  1.2663001912838916\n",
      "epoch 155 ==========================================\n",
      "Loss :  1.2564270766721655\n",
      "epoch 156 ==========================================\n",
      "Loss :  1.2466915634441547\n",
      "epoch 157 ==========================================\n",
      "Loss :  1.237096764810182\n",
      "epoch 158 ==========================================\n",
      "Loss :  1.2276457381785884\n",
      "epoch 159 ==========================================\n",
      "Loss :  1.2183414828931092\n",
      "epoch 160 ==========================================\n",
      "Loss :  1.2091869380384936\n",
      "epoch 161 ==========================================\n",
      "Loss :  1.2001849803176672\n",
      "epoch 162 ==========================================\n",
      "Loss :  1.1913384220035839\n",
      "epoch 163 ==========================================\n",
      "Loss :  1.1826500089687277\n",
      "epoch 164 ==========================================\n",
      "Loss :  1.1741224187950599\n",
      "epoch 165 ==========================================\n",
      "Loss :  1.1657582589669988\n",
      "epoch 166 ==========================================\n",
      "Loss :  1.1575600651498503\n",
      "epoch 167 ==========================================\n",
      "Loss :  1.1495302995558803\n",
      "epoch 168 ==========================================\n",
      "Loss :  1.1416713494000477\n",
      "epoch 169 ==========================================\n",
      "Loss :  1.1339855254471738\n",
      "epoch 170 ==========================================\n",
      "Loss :  1.1264750606521428\n",
      "epoch 171 ==========================================\n",
      "Loss :  1.1191421088944962\n",
      "epoch 172 ==========================================\n",
      "Loss :  1.1119887438085723\n",
      "epoch 173 ==========================================\n",
      "Loss :  1.105016957710131\n",
      "epoch 174 ==========================================\n",
      "Loss :  1.0982286606201779\n",
      "epoch 175 ==========================================\n",
      "Loss :  1.091625679386492\n",
      "epoch 176 ==========================================\n",
      "Loss :  1.085209756903146\n",
      "epoch 177 ==========================================\n",
      "Loss :  1.0789825514280889\n",
      "epoch 178 ==========================================\n",
      "Loss :  1.0729456359986607\n",
      "epoch 179 ==========================================\n",
      "Loss :  1.0671004979446908\n",
      "epoch 180 ==========================================\n",
      "Loss :  1.0614485384986387\n",
      "epoch 181 ==========================================\n",
      "Loss :  1.055991072502029\n",
      "epoch 182 ==========================================\n",
      "Loss :  1.0507293282072436\n",
      "epoch 183 ==========================================\n",
      "Loss :  1.0456644471735566\n",
      "epoch 184 ==========================================\n",
      "Loss :  1.0407974842560885\n",
      "epoch 185 ==========================================\n",
      "Loss :  1.036129407686224\n",
      "epoch 186 ==========================================\n",
      "Loss :  1.03166109924183\n",
      "epoch 187 ==========================================\n",
      "Loss :  1.0273933545054814\n",
      "epoch 188 ==========================================\n",
      "Loss :  1.0233268832087403\n",
      "epoch 189 ==========================================\n",
      "Loss :  1.0194623096603888\n",
      "epoch 190 ==========================================\n",
      "Loss :  1.015800173256391\n",
      "epoch 191 ==========================================\n",
      "Loss :  1.012340929069233\n",
      "epoch 192 ==========================================\n",
      "Loss :  1.0090849485141702\n",
      "epoch 193 ==========================================\n",
      "Loss :  1.0060325200898135\n",
      "epoch 194 ==========================================\n",
      "Loss :  1.0031838501903847\n",
      "epoch 195 ==========================================\n",
      "Loss :  1.0005390639868852\n",
      "epoch 196 ==========================================\n",
      "Loss :  0.9980982063743534\n",
      "epoch 197 ==========================================\n",
      "Loss :  0.9958612429823068\n",
      "epoch 198 ==========================================\n",
      "Loss :  0.993828061245417\n",
      "epoch 199 ==========================================\n",
      "Loss :  0.9919984715314186\n",
      "epoch 200 ==========================================\n",
      "Loss :  0.9903722083232053\n",
      "epoch 201 ==========================================\n",
      "Loss :  0.9889489314520478\n",
      "epoch 202 ==========================================\n",
      "Loss :  0.9877282273788455\n",
      "epoch 203 ==========================================\n",
      "Loss :  0.9867096105203058\n",
      "epoch 204 ==========================================\n",
      "Loss :  0.985892524616955\n",
      "epoch 205 ==========================================\n",
      "Loss :  0.9852763441398801\n",
      "epoch 206 ==========================================\n",
      "Loss :  0.9848603757331177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 207 ==========================================\n",
      "Loss :  0.9846438596886337\n",
      "epoch 208 ==========================================\n",
      "Loss :  0.9846259714508574\n",
      "epoch 209 ==========================================\n",
      "Loss :  0.9848058231477758\n",
      "current weights :  [-1.72842738 -1.62079957 -1.39367005]\n",
      "current bais :  0.5799999999999996\n"
     ]
    }
   ],
   "source": [
    "weights,bais,loss = model_training(df,inputs,weights,bais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss,color='orange')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current weights :  [-1.72842738 -1.62079957 -1.39367005]\n",
      "Current Bais :  0.5799999999999996\n",
      "Initial Loss : 2.730133488073286\n",
      "Current Loss :  0.9848058231477758\n"
     ]
    }
   ],
   "source": [
    "print('Current weights : ',weights)\n",
    "print('Current Bais : ',bais)\n",
    "print('Initial Loss :',loss[0])\n",
    "print('Current Loss : ',loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
